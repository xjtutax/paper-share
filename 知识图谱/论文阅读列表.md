
# 论文阅读列表

以知识图谱为中心，主要涉及到<font color="black">**信息抽取(实体识别、关系抽取)**</font>、知识表示(语言模型、预训练模型、图谱嵌入等)等。

持续更新中。。。



## 0. NLP综述

1. A Primer on Neural Network Modelsfor Natural Language Processing——**神经网络模型与NLP**
2. A Survey of the Usages of Deep Learning forNatural Language Processing——**NN与NLP**
3. A Survey on Deep Learning for Named Entity Recognition——**实体识别**
4. Few-Shot Named Entity Recognition: A Comprehensive Study, Jiaxin Huang——**小样本实体**
5. Recent Named Entity Recognition and Classification techniques A systematic review, ArchanaGoyal et.al.——**命名实体识别**
6. A Survey on Knowledge Graphs-Representation, Acquisition and Applications——**知识图谱**
7. A Survey on Recent Advances in Named Entity Recognition from Deep Learning models——**实体识别**
8. Deep Neural Approaches to Relation Triplets Extraction A Comprehensive Survey——**关系抽取**
9. More Data, More Relations, More Context and More Openness——**关系抽取**
10. Relation Extraction  A Survey——**关系抽取**
11. A survey of deep learning methods for relation extraction——**关系抽取**
12. Pre-Trained Models Past, Present and Future——**预训练模型**
13. Pre-trained Models for Natural Language Processing: A Survey，邱锡鹏等——**预训练模型**
14. A Survey of Transformers-transformers，邱锡鹏等——**Transformer**
15. Knowledge Graph Embedding: A Survey of Approaches and Applications——**图谱嵌入**
16. Graph embedding techniques, applications, and performance: A survey——**图谱嵌入**
17. 面向自然语言处理的深度学习研究_奚雪峰
18. 知识图谱技术综述_徐增林
19. Self-supervised Learning: Generative or Contrastive - **对比学习**
20. Graph neural networks A review of methods and applications, Jie Zhou et.al. - **图神经网络**
21. Graph Neural Networks for Natural Language Processing A Survey, Lingfei Wu et.al. - **图神经网络与NLP**
22. A Survey on Recent Advances in SequenceLabeling from Deep Learning Models, Zhiyong He et.al. - **序列标注**
23. Pre-train, Prompt, and Predict A Systematic Survey of Prompting Methods in Natural Language Processing，Pengfei Liu等——**预训练模型**



## 1. 命名实体识别

> 命名实体识别：Named Entity Recognition，简称NER，指识别文本中具有特定意义的专有名词，主要包括人名、地名、机构名等(各场景下有不同)，这些专有名词称之为命名实体。

### 1.0 扁平实体/词汇增强实体识别

1. Bidirectional LSTM-CRF Models for Sequence Tagging

2. Lattice LSTM：Chinese NER Using Lattice LSTM

3. LR-CNN:CNN-Based Chinese NER with Lexicon Rethinking

4. CGN: Leverage Lexical Knowledge for Chinese Named Entity Recognition via Collaborative Graph Network

5. LGN: A Lexicon-Based Graph Neural Network for Chinese NER

6. FLAT: Chinese NER Using Flat-Lattice Transformer

7. WC-LSTM: An Encoding Strategy Based Word-Character LSTM for Chinese NER Lattice LSTM

8. Multi-digraph: A Neural Multi-digraph Model for Chinese NER with Gazetteers

9. Simple-Lexicon：Simplify the Usage of Lexicon in Chinese NER



### 1.1 嵌套/非连续实体识别

1. A Boundary Assembling Method for Chinese Entity-Mention Recognition

2. A Boundary-aware Neural Model for Nested Named Entity Recognition

3. A Sequence-to-Set Network for Nested Named Entity Recognition

4. A FOFE-based Local Detection Approach for Named Entity Recognition and Mention Detection

5. A Span-Based Model for Joint Overlapped and Discontinuous Named Entity Recognition

6. A Supervised Multi-Head Self-Attention Network for Nested Named EntityRecognition

7. Locate and Label: A Two-stage Identifier for Nested Named Entity Recognition

8. Nested Named Entity Recognition via Explicitly Excluding the Influence of the Best Path

9. Discontinuous Named Entity Recognition as Maximal Clique Discovery

10. A Unified Generative Framework for Various NER Subtasks

11. A Boundary Regression Model for Nested Named Entity Recognition

12. Recognizing Nested Named Entity Based on the Neural Network Boundary Assembling Model

13. A Unified MRC Framework for Named Entity Recognition

14. Bipartite Flat-Graph Network for Nested Named Entity Recognition

15. Boundary Enhanced Neural Span Classification for Nested Named Entity Recognition

16. Discontinuous Named Entity Recognition as Maximal Clique Discovery

17. HIT Nested Named Entity Recognition via Head-Tail Pair and Token Interaction

18. Locate and Label A Two-stage Identifier for Nested Named Entity Recognition

19. Merge and Label A Novel Neural Network Architecture for Nested NER

20. Multi-grained Named Entity Recognition

21. Pyramid A Layered Model for Nested Named Entity Recognition

22. Sequence-to-Nuggets Nested Entity Mention Detection via Anchor-Region Networks



### 1.2 小样本/弱监督实体识别

1. Subsequence Based Deep Active Learning for Named Entity Recognition

2. Few-NERD: A Few-shot Named Entity Recognition Dataset

3. Named Entity Recognition with Small Strongly Labeled and Large Weakly Labeled Data

4. Weakly Supervised Named Entity Tagging with Learnable Logical Rules

5. Leveraging Type Descriptions for Zero-shot Named Entity Recognition and Classification

6. Learning from Miscellaneous Other-Class Words for Few-shot Named Entity Recognition

7. Template-Based Named Entity Recognition Using BART  

   

### 1.3 其他方法

1. SpanNER: Named Entity Re-/Recognition as Span Prediction

2. Improving Named Entity Recognition by External Context Retrieving and Cooperative Learning

3. Modularized Interaction Network for Named Entity Recognition

4. BERTifying the Hidden Markov Model for Multi-Source Weakly Supervised Named Entity Recognition

5. De-biasing Distantly Supervised Named Entity Recognition via Causal Intervention

6. Crowdsourcing Learning as Domain Adaptation: A Case Study on Named Entity Recognition

7. LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking

   

## 2. 实体关系抽取

> 实体关系抽取：即**关系三元组（triple）** 抽取，基于实体识别的结果，获取两个实体之间的关系，一般形式为**<实体1，*关系*，实体2>**，如<西安交通大学，*位于*，陕西>

### 2.0 句子级关系抽取

1. Omni-word Feature and Soft Constraint for Chinese Relation Extraction
2. A Novel Cascade Binary Tagging Framework for Relational Triple Extraction 
3. A Question-answering Based Framework for Relation Extraction Validation
4. Joint  extrac-tion of entities and relations based on a novel tagging scheme
5. Distant supervision for relation extraction without labeled data
6. A Relational Memory-based Embedding Model for Triple Classificationand Search Personalization
7. Pre-training Entity Relation Encoder with Intra-span and Inter-span Information
8. Relation of the Relations: A New Paradigm of the Relation Extraction Problem
9. Enriching pre-trained language model with entity information for relation classification



### 2.1 篇章级/文档级关系抽取

1. ACL2019: DocRED: A large-scale document-level relation extraction dataset 

2. ACL2019: Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network 

3. EMNLP2019: Connecting the Dots: Document-level Neural Relation Extraction with Edge-oriented Graphs

4. AAAI2019: Neural relation extraction within and across sentence boundaries

5. ACL2020: Reasoning with Latent Structure Refinement for Document-Level Relation Extraction

6. EMNLP2020: Double Graph Based Reasoning for Document-level Relation Extraction

7. EMNLP2020: Global-to-Local Neural Networks for Document-Level Relation Extraction

8. COLING2020: Document-level Relation Extraction with Dual-tier Heterogeneous Graph

9. COLING2020: Graph Enhanced Dual Attention Network for Document-Level Relation Extraction

10. COLING2020: Global Context-enhanced Graph Convolutional Networks for Document-level Relation Extraction

11. PAKDD2020: HIN: Hierarchical Inference Network for Document-Level Relation Extraction

12. Fine-tune Bert for Docred with two-step process

13. AAAI2021: Entity Structure Within and Throughout: Modeling Mention Dependencies for Document-Level Relation Extraction


### 2.2 远程监督

1. CIL: Contrastive Instance Learning Framework for Distantly Supervised Relation Extraction
2. How Knowledge Graph and Attention Help? A Qualitative Analysis into Bag-level Relation Extraction
3. SENT: Sentence-level Distant Relation Extraction via Negative Training
4. Revisiting the Negative Data of Distantly Supervised Relation Extraction



### 2.3 联合关系抽取

1. Joint Biomedical Entity and Relation Extraction with Knowledge-Enhanced Collective Inference
2. UniRE: A Unified Label Space for Entity Relation Extraction
3. PRGC: Potential Relation and Global Correspondence Based Joint Relational Triple Extraction
4. Dependency-driven Relation Extraction with Attentive Graph Convolutional Networks
5. Joint  extrac-tion of entities and relations based on a novel tagging scheme
6. A Frustratingly Easy Approach for Entity and Relation Extraction



### 2.4 开放抽取/小样本

1. CoRI: Collective Relation Integration with Data Augmentation for Open Information Extraction
2. Element Intervention for Open Relation Extraction
3. FewRel A Large-Scale Supervised Few-Shot Relation Classification Dataset with State-of-the-Art Evaluation
4. FewRel 2.0 Towards More Challenging Few-Shot Relation Classification

5. Multi-level matching and aggregation network for few-shot relation classification
6. Hybrid Attention-Based Prototypical Networks for Noisy Few-Shot Relation Classification



## 3. 预训练/知识表示/图谱嵌入

### 3.0 预训练(Pre-trained model)

1. Improving Language Understanding by Generative Pre-Training——**GPT**
2. Language Models are Unsupervised Multitask Learners——**GPT2**
3. Language Models are Few-Shot Learners——**GPT3**
4. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding——**BERT**
5. SpanBERT: Improving Pre-training by Representing and Predicting Spans——**SpanBERT**
6. XLNet: Generalized Autoregressive Pretraining for Language Understanding——**XLNet**



### 3.1 知识表示/图谱嵌入

1. TransE: Translating Embeddings for Modeling Multi-relational Data
2. TransH: Knowledge Graph Embedding by Translating on Hyperplanes
3. TransR & CTransR: Learning Entity and Relation Embeddings for Knowledge Graph Completion
4. TransD: Knowledge Graph Embedding via Dynamic Mapping Matrix
5. TransA: An Adaptive Approach for Knowledge Graph Embedding
6. Learning Hierarchy-Aware Knowledge Graph Embeddings for Link Prediction
7. InteractE: Improving Convolution-based Knowledge Graph
8. CaRe: Open Knowledge Graph Embeddings
9. Improving Knowledge Graph Embedding Using Simple Constraints
10. Differentiating Concepts and Instances for Knowledge Graph Embedding



## 4. 低资源&多模态信息抽取

1. CONTAINER Few-Shot Named Entity Recognition via Contrastive Learning——小样本
2. QaNER Prompting Question Answering Models for Few-shot Named Entity Recognition——小样本
3. A Large-Scale Chinese Multimodal NER Dataset with Speech Clues ——多模态实体
4. Domain Generalization for Named Entity Boundary Detection via Metalearning——边界检测
5. Improving Model Generalization A Chinese Named Entity Recognition Case Study——实体泛化研究
6. Few-Shot Named Entity Recognition: A Comprehensive Study, Jiaxin Huang——小样本实体
7. Few-Shot Named Entity Recognition via Meta-Learning —— 小样本
8. Template-Based Named Entity Recognition Using BART —— prompt



## 5. NLP领域的一些资源

### 5.0 NLP顶会顶刊

1. **顶会**

   ACL—— 国际计算语言学协会年会

   EMNLP —— 自然语言处理实证方法会议

   NAACL —— 北美计算语言学协会

   COLING—— 计算语言学会议

   EACL —— 欧洲计算语言学协会

   CCL——中文信息学会

2. **顶刊**

   **CL** (Computational Linguistics)

   **TACL** (Transactions of the Association for Computational Linguistics)

3. **与NLP相关的人工智能领域顶会及顶刊**

   1. **顶会**

      [AAAI](https://www.aaai.org/) —— 人工智能会议

      [IJCAL](https://www.ijcai.org/) —— 国际人工智能联合会议

      [ICML](https://icml.cc/) —— 机器学习国际会议

      [NeurIPS](https://nips.cc/) —— 神经信息处理系统年度会议

      [ACM MM](http://www.acmmm.org/2018/) —— ACM国际多媒体会议

   2. **顶刊**

      **TPAMI** (IEEE Trans on Pattern Analysis and Machine Intelligence)

      **AI** (Artificial Intelligence)

      **JMLR** (Journal of Machine Learning Research)

      

### 5.1 NLP领军团队

1. 国内：

   1. [参见中文信息学会专业委员会组成人员](http://www.cipsc.org.cn/weiyuan.php)
   2. [参见中文信息学会青年工作委员会组成人员](http://www.cipsc.org.cn/qngw/)

2. 国际：

   1. 历年顶会(前文已列出)的大会委员会成员、主席和领域主席等
   2. [CS ranking NLP国际机构学术排名](http://csrankings.org/#/fromyear/2015/toyear/2019/index?nlp&world)


### 5.2 评测与竞赛

- [SemEval | International Workshop on Semantic Evaluation](https://semeval.github.io/)

  > [Lexical and Computational Semantics and Semantic Evaluation](https://aclanthology.org/venues/semeval/)

  > 国际语义评测大会SemEval是全球范围内影响力最强、规模最大、参赛人数最多的语义评测竞赛，一年一次。除此之外，根据Google  Scholar的数据，发表在SemEval的文章在Computational  Linguistics领域的影响力仅次于ACL/EMNLP/NAACL三大会和最大的期刊TACL，位于NLP会议、期刊中的第五位。评测+会议方式，参加比赛，获得一定成绩，提交论文，经过审稿被录用。每个参赛者在完成某个task之后，可以撰写一篇论文描述自己的方法和结果并投稿到SemEval会议上。论文被接收的参赛者可以参与会议，与全球的学者一同交流探讨！

- [AI算法大赛 - 飞桨AI Studio - 人工智能学习实训社区 (baidu.com)](https://aistudio.baidu.com/aistudio/competition)

  > 百度旗下，AI Studio是基于百度深度学习平台飞桨的人工智能学习与实训社区，提供在线编程环境、免费GPU算力、海量开源算法和开放数据，帮助开发者快速创建和部署模型。

- [Kaggle](https://www.kaggle.com/)

  > Kaggle是由联合创始人、首席执行官安东尼·高德布卢姆（Anthony Goldbloom）2010年在墨尔本创立的，主要为开发商和数据科学家提供举办机器学习竞赛、托管数据库、编写和分享代码的平台。该平台已经吸引了80万名数据科学家的关注，是全球最大的数据科学类竞赛平台。

- [权威的大数据竞赛平台 - DataFountain](https://www.datafountain.cn/)

  > DataFountain（简称DF平台），是国内领先的数据竞赛服务平台和数据智能协同创新平台，旨在围绕协作、数据、知识、技能形成大数据爱好者的专业成长链路，为数据科学家及产业赋能。

- [天池大数据竞赛-天池大赛-阿里云天池 (aliyun.com)](https://tianchi.aliyun.com/competition/gameList/activeList)

  > 阿里旗下，天池大数据竞赛是由阿里巴巴集团主办，面向全球科研工作者的高端算法竞赛。通过开放海量数据和分布式计算资源，大赛让所有参与者有机会运用其设计的算法解决各类社会问题或业务问题。特别优秀的解决方案将有机会直接上线阿里巴巴旗下各电商网站（含淘宝、天猫等）或第三方合作伙伴平台，服务中国乃至世界数以亿计的用户。

- 各学会、学术会议附属评测任务，可关注官网、公众号等

  - 中国计算机学会
  - 中文信息学会
  - 以及其他



### 5.3 一些资源 

- [ACL官方资源](https://aclanthology.org/)
- [dblp: computer science bibliography](https://dblp.uni-trier.de/)
- [中国计算机学会推荐国际学术会议和期刊目录](https://www.ccf.org.cn/Academic_Evaluation/By_category/)
- [中科院分区表](http://www.fenqubiao.com/Default.aspx)
- [清华NLP](https://github.com/thunlp)

- [Papers With Code](https://paperswithcode.com/)
- [Arxiv预印本网站](https://arxiv.org/)

